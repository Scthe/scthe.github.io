---
title: "Physically based rendering notes"
excerpt: "Physically based rendering - equations + explanation"
date: 2018-06-04 12:00:00
---

{% capture image_dir %}{{ site.url }}/images/2018-06-04-pbr-notes{% endcapture %}

{::comment}
$$h_{W,b} (X)$$ - hypothesis produced by the network. We are going to assume that $$h_{W,b} (X) = y^{(L)}$$

TODO check all notation of upper/little case letters
TODO pixel/point -> fragment
{:/comment}


This is an electronic version of my notes created during [pbr-webgl](https://github.com/Scthe/pbr-webgl) project. There may be some mistakes, so be vary. We will be using point lights through this article.


## Dictionary

Let's start with list of all term that are going to be used through this article. Most of them are going to be explained in more details later (with images)

* *albedo* -
* *roughness* -
* *metallic* - the metallic-ness (0 = dielectric, 1 = metallic). This is a linear blend between two
different models. The metallic model has no diffuse component and also has a tinted incident
specular, equal to the base color
* *ambient occlusion* -
* *BRDF* -
* *attenuation* - light fall-off over distance
* *radiance* -
* fragment -
* incidence angle - angle of 0dgr. Very often in equations we will get *base* value of certain property at incidence angle, and then write function to aproximate same value at different angles

* *N* -
* *L* -
* *V* -
* $$F_0$$ - specular reflectance at normal incidence


## General algorithm

General shading algorithm can be represented using following pseudo-code:

{% highlight python linenos %}
# normal inverse square light fall-off
def attenuation (frag_pos: vec3, light: vec3):
		dist = length(frag_pos, light.pos);
		return 1 / (dist*dist)

def radiance (light):
  return light.color * attenuation(frag_pos, light)

vec3 L0 = [0.0, 0.0, 0.0]
for(light in lights):
	L0 += BRDF(camera_position, light) * radiance(light) * dot(N, L)

let ambient = vec3(0.03) * albedo * ao; # no pure black

return ambient + L0; # may want to HDR->LDR and gamma this
{% endhighlight %}


Attenuation is just a light fall-off. Given point, it describes how *strong* the light is at this point. Point closed to light source is more affected by light then the one hundreds meters away due too e.g. scattering on particles. Most well known fall-off function is inverse square of the distance:

$$ att(light, p) = \frac {1}{ ||light\_position - p|| ^2} $$

Another example is the one used in UE4 ([1] formula 9 ):

$$ att(light, p) = \frac {saturate(1 - (distance / light\_radius)^4)^2} {distance^2 + 1} $$

or just forgo it altogether:

$$ att(light, p) = 1 $$

Using attenuation we can calculate the radiance from this particular light source. Remember that we are using point lights here! If we used e.g. image based lighting, it would not be that simple. As always we multiply by $$dot(N, L)$$. Only thing left to talk about is BRDF - we will see the equations in paragraphs that follow.
Back to the algorithm, we see that in the end we also add some ambient color - pure black color does not exist in nature. It also simulates all the tiny rays of lights that bounce around, though the contribution is very low. This leaves us with final color. It's worth mentioning that this result is not clamped to any particular set of values. We have to manually do the conversion from HDR to LDR. The very popular reinhard tonemaping operator[2]:

$$ L_d (x,y) = \frac {L(x,y)}{1+L(x,y)} $$

If we want to display the final result we may want to gamma encode it first ([3]):

$$ L_{gamma} (x,y) = {L_d (x,y)} ^ {\frac{1}{2.2}} $$




## BRDF and materials properties

Bidirectional Reflectance Distribution Function (BRDF) is a function that describes how does the surface react to the incoming light. You may remember that we used BRDF in the following expression:

{% highlight python linenos %}
L0 += BRDF(camera_position, light) * radiance(light) * dot(N, L)
{% endhighlight %}

You may have noticed, that both radiance and dot(N, L) does not depend on the properties of the material the surface is made of (though normal vector may be influenced by normal map). All that stuff is hidden inside BRDF. BRDF (intuitively thought of as response to the incoming light), is a function of 2 directions over hemisphere. To represent direction over hemisphere we have to provide 2 angles per direction, which means that BRDF is a function of total 4 parameters. Alternatively, we can represent directions as vectors ($$f_r (\theta_i, \phi_i, \theta_r, \phi_r) = f_r (l,v)$$). Each material has slightly different BRDF, depending on the material properties.


{::comment} TODO image of hemisphere {:/comment}


So, how does one define material? In Disney pipeline ([4], notes below mostly mine):

* baseColor
* subsurface - used for subsurface scattering (skin, wax etc.)
* metallic
* specular
* specularTint
* roughness
* anisotropy - 0 = isotropic, 1 = maximally anisotropic
* sheen - for use with cloth
* sheenTint
* clearcoat - additional specular lobe
* clearcoat Gloss

It seems to be simpler for UE4 ([1]):

* baseColor
* metallic
* roughness
* cavity - shadowing from small geometry like seams in clothing
* subsurface - special case shader
* anisotropy - special case shader, seems to not be used very frequently
* sheen - special case shader, seems to not be used very frequently
* clearcoat - special case shader, seems to not be used very frequently

Let's say we created our material. What does it give us? Well, if we define our material based on physical properties of their real life counterparts, it should look good in 'any' lighting we put it under. That means we could reuse asset much easier. Artists from The Order: 1886 went even further. Using global shared material library (with materials like cmn_copper_a_tile_dark, cmn_copper_a_tile_worn_light, cmn_copper_a_tile_pristine_light etc.) they can even mix between material layers using masks (or even generic mask textures shared between many objects) [5].

Unfortunately, it may be somewhat difficult to create non-physically based materials, like noted in instance of Fortnite and Wreck it Ralph.




## BRDF model

There are quite a few models, but for BRDF to be physically plausible, it should satisfy following conditions:

* Reciprocity: if we switched light and eye position it should not affect results ($$ f(l,v)=f{v,l} $$)
* Energy conservation: total energy of reflected light is less or equal to the energy of incoming light

Per [1] we are going to use the following formula:

$$ f_r (l,v) = k_d * F_{Lambert} + k_s * F_{Cook-Torrance} $$

$$k_d, k_s$$ are just 'scaling factors' for diffuse and specular respectively. For dielectric, both diffuse and specular are important. In case of metals, diffuse is often black and all visible color comes from specular ($$k_d \sim= 0.0, k_s \sim= 1.0$$). Equations to derive $$k_d, k_s$$ will be slightly easier to derive after we understand better Fresnel term of $$ F_{Cook-Torrance} $$, so we wont be doing it now.

$$ F_{Lambert} (l,v) = \frac {albedo}{\pi} $$

$$ F_{Cook-Torrance} = \frac
  {F(l,h) * G(l,v,h) * D(h)}
  {4 * dot(n,l) * dot(n,v)}
$$

* l - normalized vector of reversed light direction (from fragment to light source)
* v - normalized vector of reversed view direction (from fragment to camera)
* h - halfway vector between v, l
* n - normal

Lambertian diffuse is extremely simple, so we won't waste time discussing it. On the other hand, $$ F_{Cook-Torrance} $$ microfacet specular shading model is probably a reason why You are reading this article. We will go over each term separately, but first we have to introduce microfacets.




## Microfacets

Most of popular models currently assumes that large-scale BRDF is governed by small-scale roughness. This the core idea behind the microfacet-based theories. Each microfacet has it's own normal. On the other hand, the law of reflection states that the angle of incidence($$\theta_i$$) is equal to angle of reflection ($$\theta_r$$) [6]. Imagine following situation: light ray comes from a direction **l**, reflects of the microfacet and then travels along vector **v** - straight towards the camera. This only happens when microfacet normal is equal to $$ h = \frac {l+v}{||l+v||} $$. This is called a halfway vector. As the surface consists of unountable amount of microfacets, some of them will inevitably be oriented just the right way. The question is how many of them?

![Microfacets]({{image_dir}}/microfacet.png)
*Examples of how different microfacet directions affect reflectance of seemingly flat surface*
{::comment} TODO own image {:/comment}

Microfacets are controlled by material parameter called roughness. The name is quite intitive. Very rough surface will have microfacets in all directions. This means that there always will be at least small group of facets oriented the correct way, no matter how weird the angles get. This results in very larger specular shape. Materials that are smooth (low roughness) usually have much more narrow specular shape.


![Microfacets]({{image_dir}}/ndf.png)
**
{::comment} Left: rough surface {:/comment}

![Microfacets]({{image_dir}}/ndf.png)
**
{::comment} TODO own image {:/comment}



Microfacets are much smaller then pixel. They are too small to even represent using normal maps. That's why all the equations will look more like a statistical distribution, than handpicked, artist-created values.

It's worth pointing out, that microfacet equations heavly depend on angle of both l and v. Having said that, let's go back to $$F_{Cook-Torrance}$$. As we soon shall see, every term of this formula is influenced by microfacet theory.

$$ F_{Cook-Torrance} = \frac
  {F(l,h) * G(l,v,h) * D(h)}
  {4 * dot(n,l) * dot(n,v)}
$$



## D

Normals Distribution Function (times constant)
(pi/4) * D(h)

> microfacet normal distribution function / concentration of microfacets with normals equal to h (m=h)

Examples:
	Beckmann
	Blinn-Phong
(can convert between two)



## G

> Both l, v can be blocked by other microfacets.
Visibility function
V(l,v,h) = G(l,v,h) / (dot(n,l) * dot(n,v))

> G := how many microfacets are shadowed by other microfacets (shadowing works for both stages: light->point, point->camera). All of these microfacets are already have normals pointing into halfway vector (h=m)

Examples:
	implicit (just return 1)
	Kelemen-Szirmay-Kalos
	Schlick's aprox of Cook-Torrance




## Fresnel - F(l,h)

Describes the amount of light that reflects from a mirror surface given its index of refraction. Rest of light can be e.g. refracted (meaning it will change direction at go 'into' the surface like a glass prism). The amount of reflected light heavily depend not only on angle of l, but also wavelength. We will represent this fact using RGB triplet. E.g. values of (R=1.00, G=0.71, B=0.29) mean that reflected light will have golden color (in fact, these are values for gold at $$l=0dgr$$).
Reflectance can be derived from Fresnel equations. Unfortunately, they are quite complicated, as reflectivity depends on e.g. polarization. Instead, we will write equation for reflectivity at incidence angle (0dgr) for dielectric and then provide equation with angle as parameter (per [7]).

$$f_0 = (\frac {n_1 - n_2} {n_1 + n_2}) ^2 = (\frac {1-n} {1+n}) ^2 $$

In above equation $$ n_1, n_2, n $$ mean various index of refraction (IOR). If we assume that $$n_1$$ is air, we can simplify to single parameter - index of refraction of surface. Unfortunately, this information is usually not part of material definition. Instead, following approximation is used:

$$f_{0\_aprox} = (1 - metalic) * vec3(0.04) + metalic * albedo$$

For dielectric (when $$metalic \sim= 0$$) we get static value of (R=0.04, G=0.04, B=0.04), which means almost no reflection. For metals (when $$metalic \sim= 1$$) we get value of albedo, which is default/base color of an object. This may seem counter intuitive - how can we even see specular highlight if it is same color as base object? You may remember that in our BRDF we had following parameters: $$k_d, k_s$$. In case of metals $$k_d \sim= 0.0, k_s \sim= 1.0$$. Which means, that often metals does not even have base diffuse color! In fact, metal object can be often treated as black, with all the color (e.g. golden in case of gold, red in case of copper) actually coming from specular component.

Given either of $$f_0$$ or $$f_{0\_aprox}$$, we have reflectance at incident angle 0dgr. Using Schlick's approximation we can extend this knowledge to other angles (still, it's approximation, cause some of the curves are *weird*).

$$F(f_0) = f_0 + (1 - f_0) * (1 - dot(l, v))^5 $$

If we visualize the example values of the approximation, we see that it is increasing function, reaching value of ~1.0 for 90dgr. Indeed, if we plot e.g. $$f(x) = 0.04 + (1 - 0.04) * (1 - x)^5 $$ it shows value of ~1.0 for $$x=0$$ (cosinus is equal to 0 for 90dgr), and value of 0.04 for $$x \sim= 1$$ (cosinus is equal 1 for 0dgr.)

![FresnelAngles]({{image_dir}}/fresnel_angles.jng)
**
{::comment} TODO own image {:/comment}

> Above formula is better suited for dielectrics, but ones for metals are often too complicated to be of any practical use.


## Back to kd and ks



## Final code


--------------------------------------------

[1] UE4
[2] http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf
[3] http://www.codinglabs.net/article_gamma_vs_linear.aspx
[4] Physically-Based Shading at Disney
[5] Crafting a Next-Gen Material Pipeline for The Order: 1886
[6] https://en.wikipedia.org/wiki/Reflection_(physics)
[7] https://en.wikipedia.org/wiki/Fresnel_equations#Normal_incidence

Other sources:

https://learnopengl.com/PBR/Theory
