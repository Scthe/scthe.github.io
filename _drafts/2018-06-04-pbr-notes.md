---
title: "Physically based rendering notes"
excerpt: "Physically based rendering - equations + explanation"
date: 2018-06-04 12:00:00
tags: ['Rendering', 'PBR']
---

{% capture image_dir %}/assets/2018-06-04-pbr-notes{% endcapture %}

{::comment}
TODO check all notation of upper/little case letters
TODO sources - bibtex + links in text
TODO close button design
TODO all comments
TODO check mobile - all equations
TODO add summation equation / substitute code from 1st section
TODO rename metals->metallic-like materials etc. ('metal' by itself is not correct)
TODO new syntax for images
{:/comment}


This is an electronic version of my notes created during [webgl-pbr](//github.com/Scthe/webgl-pbr) project. There may be some mistakes, so be vary. This article focuses on point lights and opaque (non-transparent) surfaces for brevity.

## Dictionary

Let's start with list of all terms used through this article. Most of them are going to be explained in more details later.

Terms:

* **albedo/diffuse** - base color of an object, usually represented as a texture.
* **roughness** - quite intuitive this one. Mirror or water are smooth (low roughness), while rock is rough (high roughness). Rough materials reflect light in more directions than smooth ones. This material parameter controls how blurry the reflections are. Usually defines roughness at microscopic scale.
* **glossiness** - opposite of roughness ($$glossiness = 1 - roughness$$). It's sometimes easier for artists to operate in this scale (white means smooth surface, black means rough).
* **metallic** - the metallic-ness (0 = dielectric, 1 = metallic) of a material. The metallic object has no diffuse component and a tinted incident specular, equal to the albedo color.
* **ambient occlusion (ao)** - trick used to approximate global illumination. Describes how *accesible* the surface is to light i.e. less accessible surface is generally darker.
* **Bidirectional Reflectance Distribution Function (BRDF)** - function  $$ f_r (\theta_l, \phi_l, \theta_v, \phi_v) $$ that describes how light is reflected from an opaque surface.
* **attenuation** - light fall-off over distance.
* **incidence angle** - angle of 0dgr. Very often in equations we will get base value of certain property at incidence angle, and then write function to approximate same value for different angles.
* **radiance** - measure of amount of light coming from angle $$ \theta $$.
* **irradiance** - sum of all incoming light (radiance).

Notation:

* **n** - normal vector of a surface (vector perpendicular to the surface)
* **l** - normalized vector from point of the surface towards the light source
* **v** - normalized vector from point of the surface towards the camera
* **m** - normal of a single microfacet
* $$F_0$$ - specular reflectance at incidence angle
* **h** -  halfway vector, calculated from following equation: $$h = \frac {l+v}{\|l+v\|}$$
* $$dot(n,l)$$ - dot product of vectors n,l. Usually I assume that both n, l are normalized
* **vec3(1.0, 1.0, 1.0)** - 3-component vector with values x=1, y=1, z=1




## General algorithm

General shading algorithm can be represented using following pseudo-code:

{% highlight python %}
# normal inverse square light fall-off
def attenuation (frag_pos: vec3, light: Light):
  dist = length(frag_pos, light.position);
  return 1 / (dist*dist)

def radiance (light):
  return light.color * attenuation(frag_pos, light)

L0 = vec3(0.0, 0.0, 0.0)
for (light in lights):
  L0 += BRDF(camera_position, light.position) * radiance(light) * dot(N, L)

ambient = vec3(0.03) * albedo * ao; # no pure black

return ambient + L0; # may want to HDR->LDR and gamma this
{% endhighlight %}
<figcaption>
General pixel shader algorithm for PBR
</figcaption>


Attenuation is just a light fall-off that describes how *strong* the incoming light is at a certain distance from light source. Point closer to light source is more affected by light than the one hundreds meters away due too e.g. scattering in the atmosphere. The most well known fall-off function is inverse square of the distance:

$$ distance(light, p) = \vert light\_position - p \vert $$

$$ attenuation(light, p) = \frac {1}{distance^2} $$

Another example is the one used in UE4 ([1], formula 9 ):

$$ attenuation(light, p) = \frac {saturate(1 - (distance / light\_radius)^4)^2} {distance^2 + 1} $$

Or just forgo it altogether:

$$ attenuation(light, p) = 1 $$

Using attenuation we can calculate the radiance for particular point light, that is then multiplied by BRDF and $$dot(N, L)$$. Since $$dot(N, L)$$ is part of practically every shading model, only thing left to talk about is BRDF - we will see the equations in paragraphs that follow.

You may have noticed that we add ambient color to the final result. It's not a physical approach, just a trick to make images look better. It useful to add some light to dark areas (as pure black color does not exist in nature).

It's worth mentioning that this result is not clamped to any particular set of values. We have to manually do the conversion from HDR to LDR. The ever popular reinhard tonemaping operator[2]:

$$ L_d (x,y) = \frac {L(x,y)}{1+L(x,y)} $$

If we want to display the final result we may want to gamma encode it first ([3]):

$$ L_{gamma} (x,y) = {L_d (x,y)} ^ {\frac{1}{2.2}} $$

After that we should be ready to present the image.




## BRDF and material representation

Bidirectional Reflectance Distribution Function (BRDF) is a function that describes how the surface reacts to the incoming light. We used BRDF in the following expression:

{% highlight python %}
for(light in lights):
  L0 += BRDF(camera_position, light) * radiance(light) * dot(N, L)
{% endhighlight %}
<figcaption>
We have to calculate response to each light that exists in the scene
</figcaption>

Both radiance and dot(N, L) does not depend on the properties of the material the surface is made of. All that stuff is hidden inside BRDF. BRDF is a function of 2 directions over hemisphere. To represent direction over hemisphere we have to provide 2 angles per direction (like polar coordinates), which means that BRDF is a function of total 4 parameters. Alternatively, we can represent directions as vectors $$ f_r (\theta_l, \phi_l, \theta_v, \phi_v) = f_r (l,v)$$. Each material has slightly different BRDF, depending on the material properties.


<figure>
  <img src="{{image_dir}}/hemisphere.png" alt=""/>
  <figcaption>
  BRDF angles. **n** is normal vector of a surface, **t** is tangent vector, **v** is view direction vector, **l** is light direction vector.
  </figcaption>
</figure>

Here is how Disney represents each material ([4]):

* baseColor
* subsurface - used for subsurface scattering (skin, wax etc.)
* metallic
* specular
* specularTint
* roughness
* anisotropy
* sheen - for use with cloth
* sheenTint
* clearcoat - additional specular lobe
* clearcoat Gloss

For comparison, main properties of material in UE4 ([1]):

* baseColor
* metallic
* roughness
* cavity - shadowing from small geometry like seams in clothing
* subsurface - special case shader
* anisotropy - special case shader, seems to not be used very frequently
* sheen - special case shader, seems to not be used very frequently
* clearcoat - special case shader, seems to not be used very frequently

Main advantage of defining materials based on physical properties of their real life counterparts, is that they should look plausible in any lighting conditions - it helps with asset reuse. Artists from The Order: 1886 described in great detail their material pipeline in [5]. Using global shared material library (with materials like cmn_copper_a_tile_dark, cmn_copper_a_tile_worn_light, cmn_copper_a_tile_pristine_light etc.) they mix between material layers using masks (often using generic mask textures shared between many objects).

Unfortunately, it may be somewhat difficult for suhc pipeline to express *non*-physically based materials, like noted in instance of Fortnite and Wreck it Ralph [1].




## Framework for physically-plausible BRDF

For BRDF to be physically plausible, it should satisfy following conditions:

* Reciprocity - if we switched light and eye position it should not affect results ($$ f_r(l,v)=f_r(v,l) $$)
* Energy conservation - total outgoing light energy should never exceed the incoming light energy (unless surface is emissive)

Most of popular BRDFs assume that resulting color is derived from two components: diffuse and specular. Diffuse is not affected by viewer direction and can be often though as *base* color of an object (at least for dielectrics). Specular depends on the viewer angle and often produces visible highlight. John Hable did an excellent work to show the relation between both of these terms in [Everything is Shiny](//filmicworlds.com/blog/everything-is-shiny/). You can read more about the process in his [How To Split Specular And Diffuse In Real Images](//filmicworlds.com/blog/how-to-split-specular-and-diffuse-in-real-images/).


![Image a) presents scissors. Image b) shows the extracted diffuse component. As shown, the handle has orange as base color. Specular component is visible on c), and it does not show any color whatsoever - it displays the specular highlights instead.]({{image_dir}}/diff-spec--scissors.jpg){: standalone }


![Diffuse component of BRDF does not depend on view angle. Specular component depends on both view angle and surface roughness]({{image_dir}}/diffuse-vs-specular.png){: standalone }


Per [1] we are going to use the following formula:

$$ f_r (l,v) = k_d * F_{Lambert} + k_s * F_{Cook-Torrance} $$

It shows the result of BRDF as being sum of diffuse ($$k_d * F_{Lambert}$$) and specular ($$k_s * F_{Cook-Torrance}$$) terms. $$k_d, k_s$$ describe amount of incoming radiance that is respectively diffused or specularly reflected. For dielectric, both diffuse and specular are important. In case of metals, diffuse is often black and all visible color comes from specular ($$k_d \approx 0.0, k_s \approx 1.0$$). Equations to derive $$k_d, k_s$$ will be given after we understand Fresnel term of $$ F_{Cook-Torrance} $$, as they are usually directly correlated. Due to energy conservation following should hold true: $$k_d + k_s \leq 1$$.

Equations for used diffuse and specular models:

$$ F_{Lambert} (l,v) = \frac {albedo}{\pi} $$

$$ F_{Cook-Torrance} = \frac
  {F(l,h) * G(l,v,h) * D(h)}
  {4 * dot(n,l) * dot(n,v)}
$$

Lambertian diffuse is extremely simple, so we won't waste time discussing it. On the other hand, $$ F_{Cook-Torrance} $$ microfacet **specular** shading model is probably a reason why You are reading this article. We will go over each term separately, but first we have to introduce microfacets.




## Microfacets

Most of popular, physically-based shading models assume that large-scale BRDF is governed by **small-scale roughness**. This the core idea behind the microfacets.


<figure>
  <img src="{{image_dir}}/general_vectors.png" alt=""/>
  <figcaption>
Notation for microfacets BRDF: **l** is reversed vector of light direction, **v** is reversed vector of view direction, **h** is halfway vector between v and l, **m** is normal of microfacet, **n** is surface normal. As we will soon discover, the light ray would reflected around microfacet normal m, not surface normal n.
  </figcaption>
</figure>

Each microfacet has it's own normal denoted **m**. Normalized vectors **l**, **v** point toward respectively light source and camera. Since we are looking for a microfacets that would reflect the light ray straight into camera, we can observe that expected m would be equal to $$ h = \frac {l+v} { \vert l + v \vert } $$. Vector h is known as a halfway vector. As the surface consists of uncountable amount of microfacets, some of them will inevitably be oriented just the right way. The question is how many of them?

Microfacets are controlled by material parameter called roughness. Very rough surface will have microfacets in all directions, which means that there always will be at least small subset of facets oriented the correct way, no matter how weird the angles get. This results in a very large specular shape. Materials that are glossy (low roughness) usually have much more narrow specular shape.


![Effect of different roughness on specular highlight. Low roughness means that specular highlight is very sharp, since there is low variance in normals of microfacets. High roughness results in larger highlight.]({{image_dir}}/other/ndf.png){: standalone }
{::comment} TODO own image {:/comment}


Microfacet equations heavily depend on angle of both l and v. Having said that, let's go back to $$F_{Cook-Torrance}$$. As we soon shall see, nearly every term of this formula is influenced by microfacet theory.

$$ F_{Cook-Torrance} = \frac
  {D(h) * G(l,v,h) * F(l,h)}
  {4 * dot(n,l) * dot(n,v)}
$$

> Microfacets are much smaller than pixel, too small to even represent using normal maps. That's why some of the equations will sometimes resemble statistical distribution.



## D(h) - Normals Distribution Function

Normal distribution function describes concentration of microfacets that are oriented towards the ideal (at least for our purposes) normal - halfway vector ($$m=h$$). This way incoming light is reflected directly into camera, resulting in stronger specular highlight. Mirror, as a glossy surface, is a perfect example. Due to low roughness, a lot of microfacets are oriented in same direction as macroscopic surface ($$ m \approx n$$). This mean that reflections are going to be really sharp, to the point that we are easily able to differentiate reflected objects. In case of mirror, distribution of normals for microfacets looks like this:

$$ D_{mirror}(h) =
\begin{cases}
\infty,  & \text{if h=n} \\
0, & \text{else}
\end{cases}
$$

> Value of distribution for normals is a scalar that is NOT constrained to 0-1!

As discussed before, surfaces with high roughness produce much larger specular shape. Value of D(h) is exactly the reason why such phenomenon exist.

![There is only a single point on surface of the mirror where h=m. For rough surfaces, there are many such points. This means that the specular shape for rough surfaces will be much larger.]({{image_dir}}/mirror-vs-rough.png){: standalone }


There are many models for D(h). Here are a selected few (helper variable $$ \alpha = roughness ^ 2 $$):

* **GGX (Trowbridge-Reitz), per [1]:**

  $$ D_{ggx}(h) = \frac {\alpha^2}
							 {\pi * ( dot(n,h)^2 * (\alpha^2 - 1) + 1) ^2}
  $$

* **Blinn-Phong, per [8]:**

	$$ D_{Blinn}(h) = \frac {1} {\pi * \alpha^2}
									* (dot(n,h)) ^(\frac {2}{\alpha^2} -2)
	$$

* **Beckmann, per [8]:**

	$$ D_{Beckmann}(h) = \frac {1} {\pi * \alpha^2 * (dot(n,h))^4}
									* e ^(\frac {(dot(n,h))^2 - 1} {\alpha^2 * (dot(n,h))^2)})
	$$



## G(l,v,h) - Visibility function

> Other names are: Shadow-Masking Term, Self-shadowing Term, Geometry Term

*Before* light ray reaches the microfacet, it can be blocked by other microfacet. *After* hitting the microfacet, light ray can also be blocked by other microfacet. Of course, optimal situation would be for ray to travel unobstructed. This fact is represented using visibility function.


![Shadowing - light ray does not reach the point where m=h, so this ray does not contribute to the specular. Masking - light ray reflects from the microfacet (where m=h), but does not reach the virtual camera.]({{image_dir}}/shadowing-masking.png){: standalone }


> The value of visibility function is a scalar, constrained between 0-1.

One of the main purposes behind visibility function is energy conservation [9]. There are many models for G(l,v,h). Here are a selected few:

* **implicit, per [8]:**

	$$ G_{implicit}(l,v,h) = dot(n,l) * dot(n,v)$$

	It nicely cancels out denominator of $$F_{Cook-Torrance}$$.

* **Cook-Torrance, per [8]:**

$$ G_{Cook-Torrance}(l,v,h) =
		min(1, \\
			\frac{ 2 (dot(n,h)) (dot(n,v)) }{dot(n,h)}, \\
			\frac{ 2 (dot(n,h)) (dot(n,l)) }{dot(n,h)}
		)
$$

* **Smith, per [10]:**

	It's been said that light ray can be blocked between light and microfacet, and also between microfacet and camera. Smith's equation takes it into consideration and breaks G into two components:

	$$ G_{Smith}(l,v,h) = G_1(l)G_1(v) $$

	where $$G_1$$ can be for example (per [1]):

	$$ k = \frac {(roughness+1)^2} {8} $$

	$$ G_1(v) =\frac {dot(n,v)} {dot(n,v) * (1-k) + k} $$

	Be sure to check [8] for more examples.





## Fresnel - F(l,h)

> Fresnel term has it's uses beside just being a term in $$F_{Cook-Torrance}$$ i.e. we are going to make use of it when calculating $$k_d, k_s$$.

Fresnel term describes the amount of light that reflects from a mirror surface given its index of refraction. Rest of light can be e.g. refracted (meaning it will change direction at go 'into' the surface). The amount of reflected light heavily depend not only on l, but also wavelength. **We will represent this fact using RGB triplet.** E.g. values of (R=1.00, G=0.71, B=0.29) mean that reflected light will have golden color (in fact, these are values for gold at $$l=0dgr$$).


![Some part of the incoming energy is refracted, some of it is reflected. Fresnel term describes how much of it is reflected.]({{image_dir}}/fresnel.png){: standalone }


Reflectance can be derived from Fresnel equations, which takes in to account e.g. polarization. This makes them very cumbersome to use. Instead, we will write equation for reflectivity at incidence angle (0dgr) and then provide equation with angle as parameter (per [7]).

$$f_0 = (\frac {n_1 - n_2} {n_1 + n_2}) ^2 = (\frac {1-n} {1+n}) ^2 $$

In above equation $$ n_1, n_2, n $$ mean various index of refraction (IOR). If we assume that $$n_1$$ is air, we can simplify to single parameter - index of refraction of surface. Unfortunately, this information is usually not part of material definition. Instead, following approximation is used:

$$f_{0\_aprox} = (1 - metalic) * vec3(0.04) + metalic * albedo$$

For dielectric (when $$metalic \approx 0$$) we get static value of [R=0.04, G=0.04, B=0.04], which means neither of wavelengths is reflected particularly strong. For metals (when $$metalic \approx 1$$) we get value of albedo, which is the base color of an object. This may seem counter intuitive - how can we even see specular highlight if it is same color as base object? You may remember that in our BRDF we had following parameters: $$k_d, k_s$$. In case of metals $$k_d \approx 0.0, k_s \approx 1.0$$. This mean that metal object can be often treated as black (negligible diffuse component), with all the color (e.g. golden in case of gold, red in case of copper) actually coming from specular component.

Given either of $$f_0$$ or $$f_{0\_aprox}$$, we have reflectance at incident angle 0dgr. Using Schlick's approximation we can extend this knowledge to other angles.

$$F(f_0) = f_0 + (1 - f_0) * (1 - dot(l, v))^5 $$

> Above formula is better suited for dielectrics, but ones for metals are often too complicated to be of any practical use.

If we visualize the example values of the approximation, we see that it is increasing function, reaching value of ~1.0 for 90dgr. Indeed, if we plot e.g. $$f(x) = 0.04 + (1 - 0.04) * (1 - x)^5 $$ it shows value of ~1.0 for $$x=0$$ (cosinus is equal to 0 for 90dgr), and value of 0.04 for $$x \approx 1$$ (cosinus is equal 1 for 0dgr.)

![Fresnel reflectance as a function of angle of incidence for different substances. Copper and aluminum have different reflectance for different wavelengths, which explains multiple curves.]({{image_dir}}/fresnel_reflectance.jpg){: standalone }



## Back to kd and ks

Let's take step back and look at our general formulas:

$$ f_r (l,v) = k_d * F_{Lambert} + k_s * F_{Cook-Torrance} $$

$$ F_{Lambert} (l,v) = \frac {albedo}{\pi} $$

$$ F_{Cook-Torrance} = \frac
  {F(l,h) * G(l,v,h) * D(h)}
  {4 * dot(n,l) * dot(n,v)}
$$

Only thing left now is to define $$k_d, k_s$$. $$k_s$$ would describe the amount of light that is reflected of the surface given angles l, v. Turns out we already calculated this value as Fresnel term F. In other words, $$F_{Cook-Torrance}$$ already 'includes' $$k_s$$, so $$k_s = 1$$.

What about $$k_d$$? It would be logical to assume that $$k_d = vec3(1.0) - k_s$$ due too conservation of energy. In fact some demos out there use this particular version of the equation. Common modification is to multiply to material's metallic property value. It's been mentioned a couple of times that metals often have black diffuse, and all of their visible color comes from specular component. We end up with following formulas [11]:

$$k_s = 1$$

$$k_d = (vec3(1.0) - kS) * (1.0 - metallic)$$

You can find more explanation on $$k_d, k_s$$ in section 9.2.2 of [12].


## TODO summmary



## Bonus: BRDF in 'Remember Me'

'Remember Me' was one of the earliest titles to make use of physically based rendering. Their whole process is extensively described [in a series of blog posts found](https://seblagarde.wordpress.com/2013/06/07/fxguide-game-environment-series-based-on-remember-me/). Used BRDF for direct light was:

$$ f_{r}(l,v) =
  \frac {albedo} {\pi}
  + F_{schlick}(specular,l,h) \\
    * \frac {SpecPower+2} {8 \pi}
    * (dot(n,h))^{SpecPower}
$$

The specular component is also known as Blinn microfacet specular BRDF. I strongly recommend to read all the articles in the series, especially ones regarding rendering of wet surfaces.



## Reference

[1] Real Shading in Unreal Engine 4
[2] https://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf
[3] https://www.codinglabs.net/article_gamma_vs_linear.aspx
[4] Physically-Based Shading at Disney
[5] Crafting a Next-Gen Material Pipeline for The Order: 1886
[6] https://en.wikipedia.org/wiki/Reflection_(physics)
[7] https://en.wikipedia.org/wiki/Fresnel_equations#Normal_incidence
[8] https://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html
[9] s2010_physically_based_shading_hoffman_a_notes
[10] Smith 1967, "Geometrical shadowing of a random rough surface"
[11] https://learnopengl.com/PBR/Theory
[12] Physically based rendering book

https://seblagarde.files.wordpress.com/2015/07/course_notes_moving_frostbite_to_pbr_v32.pdf

Physically Based Rendering Encyclopedia: https://docs.google.com/document/d/1Fb9_KgCo0noxROKN4iT8ntTbx913e-t4Wc2nMRWPzNk/edit

Terms:
  https://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html
  https://simonstechblog.blogspot.com/2011/12/microfacet-brdf.html
